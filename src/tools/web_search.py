# src/tools/web_search.py - v2.0.0
"""
Tool de b√∫squeda web usando Serper.dev (Google Search API).
Permite buscar informaci√≥n actualizada sin rate limits y con normalizaci√≥n de fechas.
"""

from typing import List, Dict, Optional
import logging
import requests
import os
from pathlib import Path

# Importar date normalizer
try:
    from src.tools.date_normalizer import DateNormalizer
except ImportError:
    DateNormalizer = None

logger = logging.getLogger(__name__)


class WebSearchTool:
    """
    Tool para realizar b√∫squedas web usando Serper.dev API.
    
    Caracter√≠sticas:
    - API de Google Search (2500 b√∫squedas gratis/mes)
    - Sin rate limits molestos
    - Normalizaci√≥n autom√°tica de fechas relativas
    - Resultados de alta calidad
    """
    
    def __init__(self, max_results: int = 5, api_key: Optional[str] = None):
        """
        Inicializa el tool de b√∫squeda web.
        
        Args:
            max_results: N√∫mero m√°ximo de resultados a retornar
            api_key: API key de Serper.dev (o la toma del .env)
        """
        self.max_results = max_results
        self.logger = logging.getLogger("minerva.websearch")
        
        # Obtener API key
        self.api_key = api_key or os.getenv('SERPER_API_KEY', '3ef61ab84a2e43cd69eb1c9518f5fb79f58e335c')
        
        # URL de Serper.dev
        self.api_url = "https://google.serper.dev/search"
        
        # Inicializar date normalizer si est√° disponible
        self.date_normalizer = DateNormalizer() if DateNormalizer else None
    
    def _normalize_query(self, query: str) -> str:
        """
        Normaliza la query convirtiendo fechas relativas a absolutas.
        
        Args:
            query: Query original
            
        Returns:
            Query con fechas normalizadas
        """
        if self.date_normalizer:
            try:
                normalized = self.date_normalizer.normalizar_fechas(query)
                if normalized != query:
                    self.logger.info(f"üìÖ Query normalizada: '{query}' ‚Üí '{normalized}'")
                return normalized
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Error normalizando fechas: {e}")
                return query
        return query
    
    def search(
        self, 
        query: str, 
        num_results: Optional[int] = None,
        normalize_dates: bool = True
    ) -> List[Dict[str, str]]:
        """
        Realiza una b√∫squeda web usando Serper.dev.
        
        Args:
            query: Consulta de b√∫squeda
            num_results: N√∫mero de resultados (usa max_results por defecto)
            normalize_dates: Si normalizar fechas relativas
            
        Returns:
            Lista de diccionarios con: title, snippet, link
        """
        try:
            # Normalizar query si es necesario
            search_query = self._normalize_query(query) if normalize_dates else query
            
            num = num_results or self.max_results
            
            self.logger.info(f"üîç Buscando en Serper.dev: '{search_query}'")
            
            # Preparar request
            headers = {
                'X-API-KEY': self.api_key,
                'Content-Type': 'application/json'
            }
            
            payload = {
                'q': search_query,
                'num': num,
                'gl': 'ar',  # Argentina
                'hl': 'es'   # Espa√±ol
            }
            
            # Realizar b√∫squeda
            response = requests.post(
                self.api_url,
                headers=headers,
                json=payload,
                timeout=10
            )
            
            response.raise_for_status()
            data = response.json()
            
            # Extraer resultados org√°nicos
            organic_results = data.get('organic', [])
            
            # Formatear resultados
            formatted_results = []
            for i, result in enumerate(organic_results[:num], 1):
                formatted_results.append({
                    'title': result.get('title', 'Sin t√≠tulo'),
                    'snippet': result.get('snippet', 'Sin descripci√≥n'),
                    'link': result.get('link', ''),
                    'position': i
                })
            
            self.logger.info(f"‚úÖ Encontrados {len(formatted_results)} resultados")
            return formatted_results
            
        except requests.exceptions.RequestException as e:
            self.logger.error(f"‚ùå Error en request a Serper.dev: {e}")
            return []
        except Exception as e:
            self.logger.error(f"‚ùå Error en b√∫squeda web: {e}")
            return []
    
    def search_news(
        self, 
        query: str, 
        num_results: Optional[int] = None,
        normalize_dates: bool = True
    ) -> List[Dict[str, str]]:
        """
        Busca noticias recientes usando Serper News API.
        
        Args:
            query: Consulta de b√∫squeda
            num_results: N√∫mero de resultados
            normalize_dates: Si normalizar fechas relativas
            
        Returns:
            Lista de noticias con: title, snippet, link, date
        """
        try:
            # Normalizar query si es necesario
            search_query = self._normalize_query(query) if normalize_dates else query
            
            num = num_results or self.max_results
            
            self.logger.info(f"üì∞ Buscando noticias en Serper.dev: '{search_query}'")
            
            # Preparar request
            headers = {
                'X-API-KEY': self.api_key,
                'Content-Type': 'application/json'
            }
            
            payload = {
                'q': search_query,
                'num': num,
                'gl': 'ar',  # Argentina
                'hl': 'es'   # Espa√±ol
            }
            
            # Usar endpoint de noticias
            news_url = "https://google.serper.dev/news"
            
            response = requests.post(
                news_url,
                headers=headers,
                json=payload,
                timeout=10
            )
            
            response.raise_for_status()
            data = response.json()
            
            # Extraer noticias
            news_results = data.get('news', [])
            
            # Formatear resultados
            formatted_results = []
            for i, result in enumerate(news_results[:num], 1):
                formatted_results.append({
                    'title': result.get('title', 'Sin t√≠tulo'),
                    'snippet': result.get('snippet', 'Sin descripci√≥n'),
                    'link': result.get('link', ''),
                    'date': result.get('date', ''),
                    'position': i
                })
            
            self.logger.info(f"‚úÖ Encontradas {len(formatted_results)} noticias")
            return formatted_results
            
        except requests.exceptions.RequestException as e:
            self.logger.error(f"‚ùå Error en request de noticias: {e}")
            return []
        except Exception as e:
            self.logger.error(f"‚ùå Error buscando noticias: {e}")
            return []
    
    def quick_answer(self, query: str) -> Optional[str]:
        """
        Intenta obtener una respuesta directa del knowledge graph.
        
        Args:
            query: Pregunta simple
            
        Returns:
            Respuesta directa si est√° disponible
        """
        try:
            self.logger.info(f"üí° Buscando respuesta r√°pida: '{query}'")
            
            headers = {
                'X-API-KEY': self.api_key,
                'Content-Type': 'application/json'
            }
            
            payload = {
                'q': query,
                'gl': 'ar',
                'hl': 'es'
            }
            
            response = requests.post(
                self.api_url,
                headers=headers,
                json=payload,
                timeout=10
            )
            
            response.raise_for_status()
            data = response.json()
            
            # Intentar extraer answer box o knowledge graph
            answer_box = data.get('answerBox')
            if answer_box:
                answer = answer_box.get('answer') or answer_box.get('snippet')
                if answer:
                    self.logger.info("‚úÖ Respuesta r√°pida encontrada")
                    return answer
            
            knowledge_graph = data.get('knowledgeGraph')
            if knowledge_graph:
                description = knowledge_graph.get('description')
                if description:
                    self.logger.info("‚úÖ Respuesta desde Knowledge Graph")
                    return description
            
            self.logger.info("‚ÑπÔ∏è No hay respuesta r√°pida disponible")
            return None
                
        except Exception as e:
            self.logger.error(f"‚ùå Error obteniendo respuesta r√°pida: {e}")
            return None


# Para testing directo
if __name__ == "__main__":
    import sys
    from pathlib import Path
    
    # Configurar logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # Agregar root al path
    ROOT_DIR = Path(__file__).parent.parent.parent
    sys.path.insert(0, str(ROOT_DIR))
    
    # Crear tool
    tool = WebSearchTool(max_results=3)
    
    # Test b√∫squeda general
    print("=== TEST 1: B√∫squeda General ===\n")
    results = tool.search("Python programming language")
    
    for i, result in enumerate(results, 1):
        print(f"{i}. {result['title']}")
        print(f"   {result['snippet'][:100]}...")
        print(f"   {result['link']}\n")
    
    # Test con normalizaci√≥n de fechas
    print("\n=== TEST 2: Normalizaci√≥n de Fechas ===\n")
    results = tool.search("cotizaci√≥n d√≥lar hoy argentina")
    
    for i, result in enumerate(results, 1):
        print(f"{i}. {result['title']}")
        print(f"   {result['link']}\n")
    
    # Test b√∫squeda de noticias
    print("\n=== TEST 3: Noticias ===\n")
    news = tool.search_news("tecnolog√≠a argentina")
    
    for i, item in enumerate(news, 1):
        print(f"{i}. {item['title']}")
        print(f"   {item['date']}")
        print(f"   {item['link']}\n")